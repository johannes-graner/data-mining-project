{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = number of random projection vectors\n",
    "# d = data dimension\n",
    "# N = number of data points\n",
    "m = 3\n",
    "d = 10\n",
    "N = 100\n",
    "eps = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample m multivariate normal vectors and scale by the norm to get\n",
    "# m vectors uniformly from the d-dimensional unit sphere\n",
    "mean = np.zeros(d)\n",
    "cov = np.eye(d)\n",
    "\n",
    "sampled = st.multivariate_normal.rvs(mean, cov, m)\n",
    "normalized_samples = np.array([row / np.linalg.norm(row) for row in sampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just generate some training data\n",
    "data = st.multivariate_normal.rvs(np.zeros(d), np.eye(d), size = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute all dot products between data vectors x_j and random projection vectors w_i\n",
    "# <w_i, x_j> = dot_products[i][j]\n",
    "dot_products = normalized_samples @ data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_products.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find minimum and maximum dot products for each w_i\n",
    "# These are the intervals which are considered to be non-anomalous\n",
    "min_values = np.array([np.min(row) for row in dot_products])\n",
    "max_values = np.array([np.max(row) for row in dot_products])\n",
    "\n",
    "inlier_intervals = np.array([ [np.min(row), np.max(row)] for row in dot_products ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-max normalization\n",
    "scaled_dot_products = np.divide(dot_products - min_values.repeat(N).reshape(m,N), (max_values - min_values).repeat(N).reshape(m,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 100)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_dot_products.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_scaled_dot_products = np.sort(scaled_dot_products, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_d_interval_indices = np.argwhere(np.diff(sorted_scaled_dot_products, axis=1) >= eps)\n",
    "outlier_break_points = [[ index[1] for index in two_d_interval_indices  if index[0] == i ] for i in range(m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_intervals = [[ [sorted_scaled_dot_products[i,index], sorted_scaled_dot_products[i,index+1]] for index in outlier_break_points[i] ] for i in range(m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.0042703461587965865, 0.17099141692006106]],\n",
       " [[0.8013201539486069, 1.0]],\n",
       " [[0.0001230418983577699, 0.14251461597498036]]]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate testing data from distribution different from training data.\n",
    "N_new = 10\n",
    "new_data = st.multivariate_normal.rvs(np.ones(d) * 2, np.eye(d), size = N_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project testing data onto the random vectors w_i\n",
    "# and check if inside inlier interval\n",
    "projection_new_data = normalized_samples @ new_data.T\n",
    "scaled_new_data = np.divide(projection_new_data.reshape(m,N_new) - min_values.repeat(N_new).reshape(m,N_new), (max_values - min_values).repeat(N_new).reshape(m,N_new))\n",
    "# inliers_new_data = np.array([projection_new_data[i] >= inlier_intervals[i][0] and projection_new_data[i] <= inlier_intervals[i][1] for i in range(m)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.0042703461587965865, 0.17099141692006106]],\n",
       " [[0.8013201539486069, 1.0]],\n",
       " [[0.0001230418983577699, 0.14251461597498036]]]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.25135726,  1.08655127,  0.8087682 ,  0.8317424 ,  0.94954866,\n",
       "         1.01614168,  1.07829789,  1.24427788,  1.33538295,  0.83206588],\n",
       "       [ 0.30539805,  0.12073241,  0.07732909, -0.08947978,  0.36831865,\n",
       "         0.29777877,  0.13189884, -0.00194933,  0.09569101,  0.50769019],\n",
       "       [ 1.0805636 ,  0.61482895,  0.82426173,  0.9576015 ,  0.44735815,\n",
       "         0.78898119,  1.18924816,  0.97623143,  0.72110488,  0.6805248 ]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_new_data = np.array(\n",
    "  [[  scaled_new_data[i][j] > 1 or \n",
    "      scaled_new_data[i][j] < 0 or \n",
    "      any([ scaled_new_data[i][j] > outlier[0] and scaled_new_data[i][j] < outlier[1] for outlier in outlier_intervals[i] ]) \n",
    "  for i in range(m)] for j in range(N_new)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_is_outlier = [ any(data_point) for data_point in outliers_new_data ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, False, True, False, True, True, True, True, False]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_is_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inliers_new_data.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "j = 30\n",
    "projection_i_j = dot_products[i][j] * normalized_samples[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(projection_i_j) - np.abs(dot_products[i][j]) < 1e-10"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
