{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class frocc:\n",
    "  def __init__(self, m, eps, d, seed=None) -> None:\n",
    "    if (seed != None):\n",
    "      np.random.seed(seed)\n",
    "    self.m = m\n",
    "    self.eps = eps\n",
    "    self.d = d\n",
    "\n",
    "    # Generate random vectors from d-dim unit sphere\n",
    "    # by x/|x|, x ~ N(0,I_d)\n",
    "    random_vectors = st.multivariate_normal.rvs(np.zeros(d), np.eye(d), m)\n",
    "    self.random_proj = np.divide(\n",
    "      random_vectors, \n",
    "      np.linalg.norm(random_vectors, axis=1).repeat(d).reshape(m,d)\n",
    "    )\n",
    "    self.outlier_intervals = np.array([])\n",
    "    self.min_values = np.array([])\n",
    "    self.max_values = np.array([])\n",
    "    \n",
    "  def train(self, data):\n",
    "    N, d_data = data.shape\n",
    "    if d_data != self.d:\n",
    "      raise ValueError(\"Dimensions must match. d = \" + str(d) + \" != \" + str(d_data) + \" = d_data.\")\n",
    "\n",
    "    # projection onto unit vector = dot product\n",
    "    dot_products = self.random_proj @ data.T\n",
    "    min_values = np.min(dot_products, axis=1)\n",
    "    max_values = np.max(dot_products, axis=1)\n",
    "\n",
    "    # Need to min-max normalize and sort projections to\n",
    "    # create outlier intervals along each projection vector\n",
    "    scaled_dot_products = np.divide(\n",
    "      dot_products - min_values.repeat(N).reshape(self.m,N),\n",
    "      (max_values - min_values).repeat(N).reshape(self.m,N)\n",
    "    )\n",
    "    sorted_scaled_dot_products = np.sort(scaled_dot_products, axis=1)\n",
    "\n",
    "    # Find indices where outlier intervals start\n",
    "    two_d_interval_indices = np.argwhere(\n",
    "      np.diff(sorted_scaled_dot_products, axis=1) >= eps\n",
    "    )\n",
    "    outlier_break_points = [[ \n",
    "      index[1] for index in two_d_interval_indices if index[0] == i \n",
    "    ] for i in range(self.m) ]\n",
    "\n",
    "    self.min_values = min_values\n",
    "    self.max_values = max_values\n",
    "    self.outlier_intervals = [[ \n",
    "      [\n",
    "        sorted_scaled_dot_products[i,index],\n",
    "        sorted_scaled_dot_products[i,index+1]\n",
    "      ] for index in outlier_break_points[i] \n",
    "    ] for i in range(self.m)]\n",
    "\n",
    "  def test(self, data):\n",
    "    N, d_data = data.shape\n",
    "    if d_data != self.d:\n",
    "      raise ValueError(\"Dimensions must match. d = \" + str(d) + \" != \" + str(d_data) + \" = d_data.\")\n",
    "\n",
    "    # Find projection of testing data and rescale\n",
    "    # to the same scale as training data\n",
    "    projection_new_data = self.random_proj @ data.T\n",
    "    scaled_new_data = np.divide(\n",
    "      projection_new_data.reshape(self.m,N) -\n",
    "        self.min_values.repeat(N).reshape(self.m,N),\n",
    "      (self.max_values - self.min_values).repeat(N).reshape(self.m,N)\n",
    "    )\n",
    "\n",
    "    # Outliers are either more extreme than any training data\n",
    "    # or are within some outlier intervals\n",
    "    outliers_new_data = np.array([\n",
    "      [  \n",
    "        scaled_new_data[i,j] > 1 or \n",
    "        scaled_new_data[i,j] < 0 or \n",
    "        any([\n",
    "          scaled_new_data[i,j] > outlier[0] and\n",
    "          scaled_new_data[i,j] < outlier[1]\n",
    "          for outlier in outlier_intervals[i] ]) \n",
    "        for i in range(self.m)\n",
    "      ]\n",
    "      for j in range(N)\n",
    "    ])\n",
    "    # print(str(outliers_new_data))\n",
    "    return np.any(outliers_new_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = number of random projection vectors\n",
    "# d = data dimension\n",
    "# N = number of data points\n",
    "m = 5\n",
    "d = 20\n",
    "N = 1000\n",
    "N_new = 100\n",
    "eps = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some training data\n",
    "np.random.seed(1000)\n",
    "data = st.multivariate_normal.rvs(np.zeros(d), np.eye(d), size = N)\n",
    "\n",
    "# And some testing data\n",
    "new_data = st.multivariate_normal.rvs(np.ones(d) * 3, np.eye(d), size = N_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector = frocc(m, eps, d, seed=1234)\n",
    "detector.train(data)\n",
    "detector.test(new_data).mean()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
